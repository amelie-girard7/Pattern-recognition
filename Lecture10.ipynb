{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 10\n",
    "\n",
    "## Last time\n",
    "\n",
    "- Subgradients\n",
    "- SGD for SVMs\n",
    "- Dual form of hard and soft SVM\n",
    "- Kernel teaser\n",
    "\n",
    "## Today (Bishop 6.1-6.2, Murphy 14.1-14.4)\n",
    "\n",
    "- Kernels\n",
    "- Kernel trick\n",
    "- Mercer's Thm\n",
    "- Examples (RBF, polynomial, etc)\n",
    "\n",
    "\n",
    "### Recall Soft-Margin SVM\n",
    "\n",
    "$\\underset{\\alpha}{\\text{max}} \\sum_{i=1}^N \\alpha_1 - \\frac{1}{2} \\sum_{i=1}^n\\sum_{j=1}^n \\alpha_i\\alpha_j y^{(i)}y^{(j)} (x^{(i)})^T x^{(j)}$\n",
    "\n",
    "At new point, predict $y=1$ if $\\theta^Tx + \\theta+0 > 0$\n",
    "\n",
    "Boundary: $\\theta^Tx + \\theta = 0$\n",
    "\n",
    "What if we have an idea of similarity that's beyond just an inner product\n",
    "\n",
    "###Recall\n",
    "\n",
    "In Hard SVM, we assume all of our features are linearly separable\n",
    "\n",
    "In Soft SVM, we assume our data is linearly seperable but there's some noise, so the data might not be\n",
    "\n",
    "\n",
    "6.034 notes on SVM\n",
    "\n",
    "Let's imagine we have just 1-dimensional data that is clearly not seprable.\n",
    "\n",
    "Might help to go to higher dimensions\n",
    "\n",
    "#### Example\n",
    "\n",
    "What if we consider the basis functions:\n",
    "\n",
    "$$\\phi(x) = (x, x^2)^T $$\n",
    "\n",
    "Or for the 2D data, let's consider\" \n",
    "\n",
    "$$\\phi(x) = (x_1, x_2, x_1x_2)^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function $k$: $\\mathcal{X} \\times \\mathcal{X} \\rightarrow \\mathbb{R} (x \\in \\mathcal{X})$ is called a **kernel** on $\\mathcal{X}$ if there is some function $\\phi: \\mathcal{X} \\rightarrow \\mathcal{Y}$ for some space $\\mathcal{F}$ with an inner product $<\\cdot,\\cdot>$ s.t. k(x,z) = <\\phi(x), \\phi(z)>\n",
    "\n",
    "$\\forall x, z, \\in \\mathcal{X}$\n",
    "\n",
    "Kernel is anything that's an inner product between our basis functions.\n",
    "\n",
    "When we refer to \"kernel trick\", or kernels for SVM, this is what we mean.\n",
    "\n",
    "Why kernels? You might have some savings by computing a kernel rather than the basis functions directly.\n",
    "\n",
    "### Example\n",
    "\n",
    "From last lectuer\n",
    "\n",
    "$$x,z \\in \\mathbb{R}^m = \\mathcal{X}$$\n",
    "\n",
    "$$\\phi(x) = (x_i x_j) 1 \\le i,j \\le m \\in \\mathbb{R}^d$$\n",
    "\n",
    "Kernel we've been seeing all along: the linear kernel\n",
    "\n",
    "### Example\n",
    "\n",
    "Linear kernel\n",
    "\n",
    "$$ x,z \\in \\mathbb{R}^m $$\n",
    "\n",
    "So we just have phi as the identity function\n",
    "\n",
    "$$ \\phi(x) = x $$\n",
    "\n",
    "And kernel is the usual inner product\n",
    "\n",
    "$$ k(x,z) = x^Ty $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "Now let's look at some other basis functions that might lead to kernels\n",
    "\n",
    "### Example\n",
    "\n",
    "We are about to introduce Gaussian basis functions.  These are not the same as the Gaussian kernel.\n",
    "\n",
    "Imagine that we have some mean, $w_1$.\n",
    "\n",
    "Then the idea of the Gaussian basis function that corresponds to \n",
    "\n",
    "$$\\phi_1(x) = \\mathcal{N}(x \\ | \\ w_1, \\sigma^2 I)$$\n",
    "\n",
    "$$\\phi_2(x) = \\mathcal{N}(x \\ | \\ w_2, \\sigma^2 I)$$\n",
    "\n",
    "Note that $w$'s have same dimensionality as $x$.\n",
    "\n",
    "Maybe I have an infinite amount of basis functions.\n",
    "\n",
    "What if I put a mean at every possible value?\n",
    "\n",
    "$$\\phi \\in \\mathbb{R}$$\n",
    "\n",
    "$$\\phi \\in \\mathbb{R}^d $$\n",
    "\n",
    "$$\\phi = (\\phi_1, \\phi_2, \\phi_3, ...)^T $$\n",
    "\n",
    "We have an infinite dimensional $\\phi$ in the last one.\n",
    "\n",
    "What if I have a function-valued $\\phi$?\n",
    "\n",
    "Function-valued $\\phi$\n",
    "\n",
    "$$\\phi: \\mathcal{X} \\rightarrow \\mathcal{F}$$\n",
    "\n",
    "$$\\phi(x)(w) = \\mathcal{N}(x \\ | \\ w, \\sigma^2I) $$\n",
    "\n",
    "$$= \\mathcal{N}(w \\ | \\ x, \\sigma^2I) $$\n",
    "\n",
    "Where we can write the equality above due to the symmetry of the normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\mathcal{X} = \\mathbb{R}^m $\n",
    "\n",
    "$ \\mathcal{F} =$ {continuous, integrable function on $\\mathbb{R}^m$}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that when we defined kernels, we required an inner product.\n",
    "\n",
    "Define an inner product on $\\mathcal{F}$.\n",
    "\n",
    "What would a function-valued inner product look like?\n",
    "\n",
    "Say that $\\forall f,g \\in \\mathcal{F}$\n",
    "\n",
    "$$<f(w),g(w)> = \\int f(w), g(w) dw $$\n",
    "\n",
    "Recall the finite dimensional inner product\n",
    "\n",
    "$$ <x,z> = x^Tz = \\sum_{i=1}^m x_iz_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our two $\\phi$ are function-valued, what will the integral be?\n",
    "\n",
    "$$ <\\phi(x),\\phi(z)> = \\int \\phi(x)(w)\\phi(z)(w)dw $$\n",
    "\n",
    "For our example before, we have Gaussians...\n",
    "\n",
    "The amazing thing about our Gaussians is that we can use the Gaussian fact and then we no longer have $w$ in both of our terms, so we can take it out of the integral\n",
    "\n",
    "$$<\\phi(x),\\phi(z)> = \\int \\mathcal{N}(x \\ | \\ z, 2 \\sigma^2I) \\mathcal{N}(w \\ | \\ c, C)dw$$\n",
    "\n",
    "$$= \\mathcal{N}(x \\ | \\ z, 2\\sigma^2I) \\int \\mathcal{N}(w \\ | \\ c, C) dw$$\n",
    "\n",
    "The integral integrates to 1!\n",
    "\n",
    "$$= \\mathcal{N}(x \\ | \\ z, 2\\sigma^2I)$$\n",
    "\n",
    "So we had $\\phi$ infinite dimensional, but $k$ is a scalar $\\in \\mathbb{R}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically:\n",
    "\n",
    "$$ k(x,z) = \\exp (\\frac{-1}{2\\sigma^2} ||x-z||^2) $$\n",
    "\n",
    "$\\sigma^2 > 0$: $\\sigma$ is called the \"bandwidth\" \"radial basis function\" (RBF) kernel\n",
    "\"Gaussian kernel\"\n",
    "\n",
    "### Example\n",
    "\n",
    "We have \n",
    "\n",
    "$$k(x,z) = (x^Tz + 1)^d$$\n",
    "\n",
    "\"degree-of-polynomial kernel\"\n",
    "\n",
    "**Definition** \"kernel trick\"\n",
    "\n",
    "Substitute $k(x,z)$ everywhere $<x,z>$ occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mercer's Thm [Scholkopf & Smola 2002]\n",
    "\n",
    "Suppose $k: \\mathcal{X} \\times \\mathcal{X} \\rightarrow \\mathbb{R}$ is symmetric\n",
    "\n",
    "Then the following are equivalent:\n",
    "\n",
    "1. $k$ is a kernel\n",
    "2. $\\forall$ square-integrable functions $f$ $\\int_{\\mathcal{X}^2} k(x,z)f(x)f(z)dxdz \\ge 0$\n",
    "3. The **Gram matrix**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$K = ...$\n",
    "\n",
    "is positive definite for any $n$ and any set of $x^{(i)}$\n",
    "\n",
    "**Corollary**\n",
    "\n",
    "k_1, k_2 kernels, then:\n",
    "\n",
    "- k_1 + k_2 kernel\n",
    "- f(x)k_1(x,z)f(z)\n",
    "- ck_1 kernel\n",
    "\n",
    "More in Bishop 6.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
